{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64ff113",
   "metadata": {},
   "source": [
    "\n",
    "**Algo4DS Assignment2**\n",
    "* Name : Priyanka Nigade\n",
    "* University Id : U01819760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f12013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from numpy.random import randint\n",
    "from math import *\n",
    "from decimal import Decimal\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24174a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from textfile\n",
    "\n",
    "path = 'iris.data'\n",
    "df = pd.read_csv(path, sep = ',')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8520fea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f378c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6884f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d65a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "for col in df.columns:\n",
    "    if col != 'class':\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658d0e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal length  150 non-null    float32\n",
      " 1   sepal width   150 non-null    float32\n",
      " 2   petal length  150 non-null    float32\n",
      " 3   petal width   150 non-null    float32\n",
      " 4   class         150 non-null    object \n",
      "dtypes: float32(4), object(1)\n",
      "memory usage: 3.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad4332c",
   "metadata": {},
   "source": [
    "### Divide 20/30 (instances of esch class) Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618ed020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45af3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 20 instances and combine them to create train/reference dataset\n",
    "\n",
    "df_iris_setosa = df1[df1['class'] == 'Iris-setosa'][:20]\n",
    "df_iris_versicolor = df1[df1['class'] == 'Iris-versicolor'][:20]\n",
    "df_iris_virginica = df1[df1['class'] == 'Iris-virginica'][:20]\n",
    "\n",
    "train_set = pd.concat([df_iris_setosa, df_iris_versicolor, df_iris_virginica])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "006e2679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width            class\n",
       "0             5.1          3.5           1.4          0.2      Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2      Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2      Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2      Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2      Iris-setosa\n",
       "5             5.4          3.9           1.7          0.4      Iris-setosa\n",
       "6             4.6          3.4           1.4          0.3      Iris-setosa\n",
       "7             5.0          3.4           1.5          0.2      Iris-setosa\n",
       "8             4.4          2.9           1.4          0.2      Iris-setosa\n",
       "9             4.9          3.1           1.5          0.1      Iris-setosa\n",
       "10            5.4          3.7           1.5          0.2      Iris-setosa\n",
       "11            4.8          3.4           1.6          0.2      Iris-setosa\n",
       "12            4.8          3.0           1.4          0.1      Iris-setosa\n",
       "13            4.3          3.0           1.1          0.1      Iris-setosa\n",
       "14            5.8          4.0           1.2          0.2      Iris-setosa\n",
       "15            5.7          4.4           1.5          0.4      Iris-setosa\n",
       "16            5.4          3.9           1.3          0.4      Iris-setosa\n",
       "17            5.1          3.5           1.4          0.3      Iris-setosa\n",
       "18            5.7          3.8           1.7          0.3      Iris-setosa\n",
       "19            5.1          3.8           1.5          0.3      Iris-setosa\n",
       "50            7.0          3.2           4.7          1.4  Iris-versicolor\n",
       "51            6.4          3.2           4.5          1.5  Iris-versicolor\n",
       "52            6.9          3.1           4.9          1.5  Iris-versicolor\n",
       "53            5.5          2.3           4.0          1.3  Iris-versicolor\n",
       "54            6.5          2.8           4.6          1.5  Iris-versicolor\n",
       "55            5.7          2.8           4.5          1.3  Iris-versicolor\n",
       "56            6.3          3.3           4.7          1.6  Iris-versicolor\n",
       "57            4.9          2.4           3.3          1.0  Iris-versicolor\n",
       "58            6.6          2.9           4.6          1.3  Iris-versicolor\n",
       "59            5.2          2.7           3.9          1.4  Iris-versicolor\n",
       "60            5.0          2.0           3.5          1.0  Iris-versicolor\n",
       "61            5.9          3.0           4.2          1.5  Iris-versicolor\n",
       "62            6.0          2.2           4.0          1.0  Iris-versicolor\n",
       "63            6.1          2.9           4.7          1.4  Iris-versicolor\n",
       "64            5.6          2.9           3.6          1.3  Iris-versicolor\n",
       "65            6.7          3.1           4.4          1.4  Iris-versicolor\n",
       "66            5.6          3.0           4.5          1.5  Iris-versicolor\n",
       "67            5.8          2.7           4.1          1.0  Iris-versicolor\n",
       "68            6.2          2.2           4.5          1.5  Iris-versicolor\n",
       "69            5.6          2.5           3.9          1.1  Iris-versicolor\n",
       "100           6.3          3.3           6.0          2.5   Iris-virginica\n",
       "101           5.8          2.7           5.1          1.9   Iris-virginica\n",
       "102           7.1          3.0           5.9          2.1   Iris-virginica\n",
       "103           6.3          2.9           5.6          1.8   Iris-virginica\n",
       "104           6.5          3.0           5.8          2.2   Iris-virginica\n",
       "105           7.6          3.0           6.6          2.1   Iris-virginica\n",
       "106           4.9          2.5           4.5          1.7   Iris-virginica\n",
       "107           7.3          2.9           6.3          1.8   Iris-virginica\n",
       "108           6.7          2.5           5.8          1.8   Iris-virginica\n",
       "109           7.2          3.6           6.1          2.5   Iris-virginica\n",
       "110           6.5          3.2           5.1          2.0   Iris-virginica\n",
       "111           6.4          2.7           5.3          1.9   Iris-virginica\n",
       "112           6.8          3.0           5.5          2.1   Iris-virginica\n",
       "113           5.7          2.5           5.0          2.0   Iris-virginica\n",
       "114           5.8          2.8           5.1          2.4   Iris-virginica\n",
       "115           6.4          3.2           5.3          2.3   Iris-virginica\n",
       "116           6.5          3.0           5.5          1.8   Iris-virginica\n",
       "117           7.7          3.8           6.7          2.2   Iris-virginica\n",
       "118           7.7          2.6           6.9          2.3   Iris-virginica\n",
       "119           6.0          2.2           5.0          1.5   Iris-virginica"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38158129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first 30 instances and combine them to create test dataset\n",
    "\n",
    "df_iris_setosa = df1[df1['class'] == 'Iris-setosa'][20:50]\n",
    "df_iris_versicolor = df1[df1['class'] == 'Iris-versicolor'][20:50]\n",
    "df_iris_virginica = df1[df1['class'] == 'Iris-virginica'][20:50]\n",
    "\n",
    "test_set = pd.concat([df_iris_setosa, df_iris_versicolor, df_iris_virginica])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d3f89d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "20            5.4          3.4           1.7          0.2     Iris-setosa\n",
       "21            5.1          3.7           1.5          0.4     Iris-setosa\n",
       "22            4.6          3.6           1.0          0.2     Iris-setosa\n",
       "23            5.1          3.3           1.7          0.5     Iris-setosa\n",
       "24            4.8          3.4           1.9          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b51825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    \n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce63d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to calculate Manhattan distance \n",
    "def manhattan_distance(a, b):\n",
    "    distance = 0.0\n",
    "\n",
    "    for i in range(len(a)-1):\n",
    "        distance += abs(a[i] - b[i])\n",
    "    \n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53541386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function distance between two points\n",
    "\n",
    "def p_root(value, root):\n",
    "     \n",
    "    root_value = 1 / float(root)\n",
    "    return round (Decimal(value) **\n",
    "             Decimal(root_value), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e836b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to calculate minkowski distance \n",
    "\n",
    "def minkowski_distance(x, y, p_value):\n",
    "   \n",
    "    # pass the p_root function to calculate\n",
    "    # all the value of vector parallelly\n",
    "    return (p_root(sum(pow(abs(a-b), p_value)\n",
    "            for a, b in zip(x, y)), p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ded6a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, k_neighbors, distancemethod, p, power):\n",
    "    distances = list()\n",
    "    weighted_distance = list()\n",
    "       \n",
    "    #remove class from test set row\n",
    "    test_row.pop()\n",
    "    for train_row in train:\n",
    "        if(distancemethod == 'euclidean'):\n",
    "            dist = euclidean_distance(test_row, train_row)\n",
    "            distances.append((train_row, dist))\n",
    "            \n",
    "        elif(distancemethod == 'manhattan'):\n",
    "            \n",
    "            dist = manhattan_distance(test_row, train_row)\n",
    "            distances.append((train_row, dist))\n",
    "            \n",
    "        elif(distancemethod == 'minkowski'):           \n",
    "            # p value needed\n",
    "            train_row_new = train_row[:-1]\n",
    "            dist = minkowski_distance(test_row, train_row_new, p)\n",
    "            \n",
    "            #Library function does not accept .5 value\n",
    "            #dist = distance.minkowski(test_row, train_row_new, p)\n",
    "            distances.append((train_row, dist))\n",
    "            \n",
    "        else:\n",
    "            print('Please provide valid method to calculate distance')\n",
    "\n",
    "    # sort the distances\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    class_values = list()\n",
    "    #distances1 = distances\n",
    "\n",
    "    if(power == 0):\n",
    "        for i in range(k_neighbors):\n",
    "            neighbors.append(distances[i][0])\n",
    "    else:\n",
    "        for i in range(k_neighbors):\n",
    "            # ckeck if distance is 0 to avoid divide by 0 error\n",
    "            if distances[i][1]** power == 0:\n",
    "                weighted_distance.append((distances[i][0],0))                               \n",
    "                \n",
    "            else:\n",
    "                weighted_distance.append((distances[i][0], 1/ ((distances[i][1])** power)))\n",
    "                \n",
    "            class_values.append(distances[i][0][4])\n",
    "            \n",
    "        class_values = set(class_values)      \n",
    "        final_weight_class = list()\n",
    "\n",
    "        #Get the sum of weighted distance for each class\n",
    "        for val in class_values:\n",
    "            sum = 0\n",
    "            for value in weighted_distance: \n",
    "                \n",
    "                clas = value[0][4]\n",
    "                if val == clas:\n",
    "                    sum += value[1]\n",
    "            \n",
    "            final_weight_class.append((val, sum)) \n",
    "        \n",
    "        #sort the added distances\n",
    "        final_weight_class.sort(key=lambda tup: tup[1]) \n",
    "        \n",
    "        # Return class with min distance\n",
    "        neighbors.append(final_weight_class[0][0])\n",
    "        \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211fe241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, k_neighbors, distancemethod, p, power):\n",
    "    neighbors = get_neighbors(train, test_row, k_neighbors, distancemethod, p, power)\n",
    "    \n",
    "    if power <= 0:\n",
    "        output_values = [row[-1] for row in neighbors]\n",
    "    \n",
    "        #print('output_values', output_values)\n",
    "        #from list of class values in the neighbors, the max() function takes a set of unique class values \n",
    "        #and calls the count on the list of class values for each class value in the set.\n",
    "        # works same as voting class with min distance\n",
    "        prediction = max(set(output_values), key=output_values.count)\n",
    "        \n",
    "    else:\n",
    "        prediction = neighbors[0]\n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf369707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN Algorithm\n",
    "# Parameters \n",
    "    # train is the train dataset\n",
    "    # test is the test dataset\n",
    "    # k_neighbors = no. of numbers need to find out\n",
    "    # distancemethod = method for distance calculation\n",
    "    # p for minkowski distance calculations\n",
    "    # power for weighted distance KNN\n",
    "    \n",
    "def get_nearest_neighbors_predictions(train, test, k_neighbors, distancemethod, p = 0, power = 0):\n",
    "    if 'predicted' in test.columns:\n",
    "        test = test.drop(['predicted'], axis = 1)\n",
    "        \n",
    "    predictions = list()\n",
    "    \n",
    "    train_list = train.values.tolist()\n",
    "    test_list = test.values.tolist()\n",
    "\n",
    "    for row in test_list:\n",
    "        output = predict_classification(train_list, row, k_neighbors, distancemethod, p, power)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2a67843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error(test_set, predictions):\n",
    "        \n",
    "    test_set_predictions = test_set\n",
    "    test_set_predictions['predicted'] = predictions\n",
    "    accuracy= (len(test_set_predictions[test_set_predictions['class'] == test_set_predictions['predicted']])/len(test_set))* 100.0 \n",
    "    error= (len(test_set_predictions[test_set_predictions['class'] != test_set_predictions['predicted']])/len(test_set))* 100.0\n",
    "    print('=============================================')\n",
    "    print('KNN Algorithm Performance')\n",
    "    print('=============================================')\n",
    "    print('Percentage Accuracy :', accuracy)\n",
    "    print('Percentage Error    :', error)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58b06db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(test_set, predictions, p):\n",
    "        \n",
    "    test_set_predictions = test_set\n",
    "    test_set_predictions['predicted'] = predictions\n",
    "    accuracy= (len(test_set_predictions[test_set_predictions['class'] == test_set_predictions['predicted']])/len(test_set))* 100.0 \n",
    "    error= (len(test_set_predictions[test_set_predictions['class'] != test_set_predictions['predicted']])/len(test_set))* 100.0\n",
    "    print('=============================================')\n",
    "    print('KNN Algorithm Performance')\n",
    "    print('=============================================')\n",
    "    print('P value :', p)\n",
    "    \n",
    "    print('Percentage Accuracy :', accuracy)\n",
    "    print('Percentage Error    :', error)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c4857",
   "metadata": {},
   "source": [
    "#### Q 1. Find the number of errors of the nearest neighbor classifier. <br>\n",
    "NN-classifier(q, R) = t(argmind(q, r))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;r∈R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02693fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set, test_set, k_neighbors=1, distancemethod ='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d031c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 92.22222222222223\n",
      "Percentage Error    : 7.777777777777778\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90224dc",
   "metadata": {},
   "source": [
    "#### Q 2. Find the number of errors of the (k = 3)-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a3a6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set, test_set,k_neighbors= 3, distancemethod ='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2312e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 93.33333333333333\n",
      "Percentage Error    : 6.666666666666667\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdccb0e",
   "metadata": {},
   "source": [
    "#### Q 3. Find the number of errors of the (k = 5)-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5691d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set, test_set, k_neighbors=5, distancemethod ='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84f0a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41329ed",
   "metadata": {},
   "source": [
    "#### Q 4. Find the number of errors of the (k = 3)-NN classifier where Manhattan L1 distance is used instead of L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0574d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set, test_set, k_neighbors=3, distancemethod = 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d38790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 93.33333333333333\n",
      "Percentage Error    : 6.666666666666667\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d3ff8",
   "metadata": {},
   "source": [
    "#### Q 5. Find the number of errors of the (p = 1) distance weighted (k = 5)-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0474264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_nearest_neighbors_predictions(train_set, test_set, \n",
    "                                                k_neighbors=5, distancemethod = 'euclidean', p=0, power =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cdc0a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 86.66666666666667\n",
      "Percentage Error    : 13.333333333333334\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff337727",
   "metadata": {},
   "source": [
    "#### Q 6. Find the number of errors of the (p = 2) distance weighted (k = 5)-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c279a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_nearest_neighbors_predictions(train_set, test_set, \n",
    "                                               k_neighbors=5, distancemethod = 'euclidean', p=0, power=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ac460ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 86.66666666666667\n",
      "Percentage Error    : 13.333333333333334\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set, predictions)"
   ]
  },
  {
   "attachments": {
    "normalized.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6f59b8f9",
   "metadata": {},
   "source": [
    "#### Q 9. Find the normalized vectors for the first instance of each class.\n",
    "![normalized.png](attachment:normalized.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5edd2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_set.drop(['predicted'], axis =1)\n",
    "train_set_normalized = train_set.copy()\n",
    "test_set_normalized = test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "122759af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a0ecfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the min max of the column\n",
    "def min_max_scaling(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5beb6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the values\n",
    "for col in train_set_normalized.columns:\n",
    "    if col != 'class':\n",
    "        train_set_normalized[col] = min_max_scaling(train_set_normalized[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d9f3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_set_normalized.columns:\n",
    "    if col != 'class':\n",
    "        test_set_normalized[col] = min_max_scaling(test_set_normalized[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3277054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "20       0.285714     0.578947      0.122807     0.041667     Iris-setosa\n",
       "21       0.200000     0.736842      0.087719     0.125000     Iris-setosa\n",
       "22       0.057143     0.684211      0.000000     0.041667     Iris-setosa\n",
       "23       0.200000     0.526316      0.122807     0.166667     Iris-setosa\n",
       "24       0.114286     0.578947      0.157895     0.041667     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145      0.657143     0.368421      0.736842     0.916667  Iris-virginica\n",
       "146      0.542857     0.105263      0.701754     0.750000  Iris-virginica\n",
       "147      0.600000     0.368421      0.736842     0.791667  Iris-virginica\n",
       "148      0.514286     0.578947      0.771930     0.916667  Iris-virginica\n",
       "149      0.428571     0.368421      0.719298     0.708333  Iris-virginica\n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9bdcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20d1d7",
   "metadata": {},
   "source": [
    "#### Q 10. Find the number of errors of the nearest neighbor classifier if Euclidean L2 distance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3080b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=1, distancemethod ='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "456ec397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 94.44444444444444\n",
      "Percentage Error    : 5.555555555555555\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set_normalized, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f4346",
   "metadata": {},
   "source": [
    "#### Q 11. Find the p value that gives the least error rate of the nearest neighbor classifier when Minkowski Lp is used. Try p = 0.5 ∼ 2.5 incremented by 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cee5498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 0.5\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 0.6\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 0.7\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 0.7999999999999999\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 0.8999999999999999\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 0.9999999999999999\n",
      "Percentage Accuracy : 94.44444444444444\n",
      "Percentage Error    : 5.555555555555555\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.0999999999999999\n",
      "Percentage Accuracy : 94.44444444444444\n",
      "Percentage Error    : 5.555555555555555\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.2\n",
      "Percentage Accuracy : 94.44444444444444\n",
      "Percentage Error    : 5.555555555555555\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.3\n",
      "Percentage Accuracy : 94.44444444444444\n",
      "Percentage Error    : 5.555555555555555\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.4000000000000001\n",
      "Percentage Accuracy : 94.44444444444444\n",
      "Percentage Error    : 5.555555555555555\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.5000000000000002\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.6000000000000003\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.7000000000000004\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.8000000000000005\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 1.9000000000000006\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 2.0000000000000004\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 2.1000000000000005\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 2.2000000000000006\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 2.3000000000000007\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 2.400000000000001\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "P value : 2.500000000000001\n",
      "Percentage Accuracy : 95.55555555555556\n",
      "Percentage Error    : 4.444444444444445\n",
      "\n",
      "\n",
      "=============================================\n",
      "Best p value: 0.5\n",
      "Min error for best p value: 4.444444444444445\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "p_val_error = list()\n",
    "\n",
    "while p < 2.6:\n",
    "    predictions = get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=1, distancemethod ='minkowski', p = p)\n",
    "    error_val = calculate_error(test_set_normalized, predictions, p)\n",
    "    p_val_error.append((p, error_val))\n",
    "    p = p+0.1\n",
    "    \n",
    "p_val_error.sort(key=lambda tup: tup[1])\n",
    "\n",
    "print('\\n\\n=============================================')\n",
    "print('Best p value:', p_val_error[0][0])\n",
    "print('Min error for best p value:', p_val_error[0][1])\n",
    "print('=============================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80a41f",
   "metadata": {},
   "source": [
    "#### Q 12. Find the number of errors of the (k = 3)-NN classifier if Euclidean L2 distance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8907228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=3, distancemethod = 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b1437d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 93.33333333333333\n",
      "Percentage Error    : 6.666666666666667\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set_normalized, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c6276",
   "metadata": {},
   "source": [
    "#### Q 13. Find the number of errors of the (k = 5)-NN classifier if Euclidean L2 distance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84950fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=5, distancemethod = 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b165488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 92.22222222222223\n",
      "Percentage Error    : 7.777777777777778\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set_normalized, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482b8b9",
   "metadata": {},
   "source": [
    "#### Q 14. Find the number of errors of the (p = 1) distance weighted (k = 5)-NN classifier if Euclidean L2 distance is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22537f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=5, distancemethod = 'euclidean', p=0, power=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56bd7737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 71.11111111111111\n",
      "Percentage Error    : 28.888888888888886\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set_normalized, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba4d681",
   "metadata": {},
   "source": [
    "#### Q 15. Find the number of errors of the (p = 2) distance weighted (k = 5)-NN classifier if Euclidean L2 distance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2927bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=5, distancemethod = 'euclidean', p=0, power=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e14eec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 71.11111111111111\n",
      "Percentage Error    : 28.888888888888886\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set_normalized, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "278aa09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= get_nearest_neighbors_predictions(train_set_normalized, test_set_normalized, \n",
    "                                               k_neighbors=5, distancemethod = 'euclidean', p=0, power=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a293975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "KNN Algorithm Performance\n",
      "=============================================\n",
      "Percentage Accuracy : 71.11111111111111\n",
      "Percentage Error    : 28.888888888888886\n"
     ]
    }
   ],
   "source": [
    "find_error(test_set_normalized, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945fe7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
