# KNN_from_scratch

# K-Nearest Neighbors (KNN) Classification Algorithm from Scratch

## Overview
This Python project implements the K-Nearest Neighbors (KNN) classification algorithm from scratch without using the scikit-learn library. It provides a flexible and customizable implementation that allows you to choose from three different distance calculation methods: Euclidean, Manhattan, and Minkowski.

**Distance Calculation Methods**

* Euclidean: The Euclidean distance is the standard "as-the-crow-flies" distance between two points.
* Manhattan: The Manhattan distance, also known as the "taxicab distance," is the sum of the absolute differences of their coordinates.
* Minkowski: The Minkowski distance generalizes both the Euclidean and Manhattan distances. You can specify the value of 'p' to adjust the calculation. (p=2 for Euclidean, p=1 for Manhattan)

**How to use**

* You can customize and fine-tune the KNN classifier by modifying the parameters in the code.

* Run your KNN classifier by executing the `ML_KNN_without_SKLearn.jpynb` script. You can choose the distance calculation method by specifying it as a parameter.


**Happy classifying with K-Nearest Neighbors!**
